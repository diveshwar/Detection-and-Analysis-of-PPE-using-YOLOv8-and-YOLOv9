{"cells":[{"cell_type":"code","execution_count":null,"id":"86b3fd8e-8e13-4f17-b683-1a523aa10d47","metadata":{"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"86b3fd8e-8e13-4f17-b683-1a523aa10d47","executionInfo":{"status":"ok","timestamp":1713703102803,"user_tz":-330,"elapsed":5,"user":{"displayName":"Palani P","userId":"17724790012365390628"}},"outputId":"e3ffa2c8-1126-4397-d34e-e3c10871c37b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Apr 21 12:38:22 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   48C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/newyolov9"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EBzcTVU4qzkP","executionInfo":{"status":"ok","timestamp":1730650129049,"user_tz":-330,"elapsed":889,"user":{"displayName":"Palani P","userId":"17724790012365390628"}},"outputId":"4594bfd5-9790-425a-a6e7-42595145c7b0"},"id":"EBzcTVU4qzkP","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: '/content/drive/MyDrive/newyolov9'\n","/content\n"]}]},{"cell_type":"code","execution_count":null,"id":"fc3264d1-0abc-4ccc-b730-869922c7b544","metadata":{"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"fc3264d1-0abc-4ccc-b730-869922c7b544","executionInfo":{"status":"ok","timestamp":1713703184298,"user_tz":-330,"elapsed":2636,"user":{"displayName":"Palani P","userId":"17724790012365390628"}},"outputId":"4d0eaae3-1283-4515-906b-5c4c7a031b35"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov9'...\n","remote: Enumerating objects: 668, done.\u001b[K\n","remote: Counting objects: 100% (47/47), done.\u001b[K\n","remote: Compressing objects: 100% (39/39), done.\u001b[K\n","remote: Total 668 (delta 24), reused 23 (delta 8), pack-reused 621\u001b[K\n","Receiving objects: 100% (668/668), 3.24 MiB | 6.57 MiB/s, done.\n","Resolving deltas: 100% (263/263), done.\n"]}],"source":["!git clone https://github.com/WongKinYiu/yolov9.git"]},{"cell_type":"code","execution_count":null,"id":"bd27d4bc-acba-4b21-8e13-e78b7ee01acb","metadata":{"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"bd27d4bc-acba-4b21-8e13-e78b7ee01acb","executionInfo":{"status":"ok","timestamp":1713703203687,"user_tz":-330,"elapsed":535,"user":{"displayName":"Palani P","userId":"17724790012365390628"}},"outputId":"d07749a8-89d7-485f-f600-d4346a9ef330"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/newyolov9/yolov9\n"]}],"source":["%cd /content/drive/MyDrive/newyolov9/yolov9"]},{"cell_type":"code","execution_count":null,"id":"c75fe521-6974-4ae4-b76d-71e1789947a0","metadata":{"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"c75fe521-6974-4ae4-b76d-71e1789947a0","executionInfo":{"status":"ok","timestamp":1713703281234,"user_tz":-330,"elapsed":76034,"user":{"displayName":"Palani P","userId":"17724790012365390628"}},"outputId":"6b1f68ee-7925-4bd4-d4e8-8ed54a44a987"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gitpython (from -r requirements.txt (line 5))\n","  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/207.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m204.8/207.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (7.34.0)\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.25.2)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (4.8.0.76)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (9.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (5.9.5)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (1.11.4)\n","Collecting thop>=0.1.1 (from -r requirements.txt (line 15))\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (2.2.1+cu121)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (0.17.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (4.66.2)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (2.15.2)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (2.0.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.13.1)\n","Requirement already satisfied: albumentations>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 46)) (1.3.1)\n","Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 47)) (2.0.7)\n","Collecting gitdb<5,>=4.0.1 (from gitpython->-r requirements.txt (line 5))\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 6)) (67.7.2)\n","Collecting jedi>=0.16 (from ipython->-r requirements.txt (line 6))\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 6)) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 6)) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 6)) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 6)) (3.0.43)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 6)) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 6)) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 6)) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 6)) (4.9.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (24.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (2024.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.7.0->-r requirements.txt (line 16))\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.7.0->-r requirements.txt (line 16))\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.7.0->-r requirements.txt (line 16))\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.7.0->-r requirements.txt (line 16))\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.7.0->-r requirements.txt (line 16))\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.7.0->-r requirements.txt (line 16))\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.7.0->-r requirements.txt (line 16))\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.7.0->-r requirements.txt (line 16))\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.7.0->-r requirements.txt (line 16))\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.7.0->-r requirements.txt (line 16))\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.7.0->-r requirements.txt (line 16))\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->-r requirements.txt (line 16))\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.62.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.6)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.20.3)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.0.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.1)\n","Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations>=1.0.3->-r requirements.txt (line 46)) (0.19.3)\n","Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations>=1.0.3->-r requirements.txt (line 46)) (0.0.4)\n","Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations>=1.0.3->-r requirements.txt (line 46)) (4.9.0.80)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->-r requirements.txt (line 5))\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 22)) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 22)) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 22)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.3.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 6)) (0.8.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 6)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 6)) (0.2.13)\n","Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations>=1.0.3->-r requirements.txt (line 46)) (1.2.2)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations>=1.0.3->-r requirements.txt (line 46)) (2.31.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations>=1.0.3->-r requirements.txt (line 46)) (2024.2.12)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations>=1.0.3->-r requirements.txt (line 46)) (1.6.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 22)) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->-r requirements.txt (line 16)) (1.3.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 22)) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations>=1.0.3->-r requirements.txt (line 46)) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations>=1.0.3->-r requirements.txt (line 46)) (3.4.0)\n","Installing collected packages: smmap, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, nvidia-cusparse-cu12, nvidia-cudnn-cu12, gitdb, nvidia-cusolver-cu12, gitpython, thop\n","Successfully installed gitdb-4.0.11 gitpython-3.1.43 jedi-0.19.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 smmap-5.0.1 thop-0.1.1.post2209072238\n"]}],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"id":"fc035ddc-c3da-444b-9ba5-5f5c7876ab58","metadata":{"tags":[],"id":"fc035ddc-c3da-444b-9ba5-5f5c7876ab58"},"outputs":[],"source":["!wget -P /content/drive/MyDrive/newyolov9 -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt\n","!wget -P /content/drive/MyDrive/newyolov9 -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-e.pt"]},{"cell_type":"code","execution_count":null,"id":"ef84de5b-3fad-4ebb-ba78-4569776b75a8","metadata":{"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"ef84de5b-3fad-4ebb-ba78-4569776b75a8","executionInfo":{"status":"ok","timestamp":1713703321208,"user_tz":-330,"elapsed":4,"user":{"displayName":"Palani P","userId":"17724790012365390628"}},"outputId":"27420618-e50f-459c-ba2d-221e2202b787"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/newyolov9\n"]}],"source":["%cd /content/drive/MyDrive/newyolov9"]},{"cell_type":"code","execution_count":null,"id":"d7e04f28-72bd-4c45-b4bc-afb8a45e2fd9","metadata":{"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"d7e04f28-72bd-4c45-b4bc-afb8a45e2fd9","executionInfo":{"status":"ok","timestamp":1713703369290,"user_tz":-330,"elapsed":19476,"user":{"displayName":"Palani P","userId":"17724790012365390628"}},"outputId":"58602667-8ffa-4ad0-e9ef-22f576dabf73"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.27)\n","Requirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2023.7.22)\n","Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n","Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.10.0)\n","Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.10)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n","Requirement already satisfied: opencv-python-headless==4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.8.0.74)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n","Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.2)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n","Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n","Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.4.27)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.51.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n","loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in PPE_Detection-2 to yolov9:: 100%|██████████| 198176/198176 [00:05<00:00, 39214.18it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to PPE_Detection-2 in yolov9:: 100%|██████████| 6472/6472 [00:01<00:00, 4686.06it/s]\n"]}],"source":["!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"8joVH7TL2k5V6uScFBEy\")\n","project = rf.workspace(\"project-uyrxf\").project(\"ppe_detection-v1x3l\")\n","version = project.version(2)\n","dataset = version.download(\"yolov9\")\n"]},{"cell_type":"code","execution_count":null,"id":"da369521-144c-4a81-bf18-da8382ee6a6c","metadata":{"tags":[],"id":"da369521-144c-4a81-bf18-da8382ee6a6c","outputId":"e3e05091-5f4e-4acf-838b-a447b1b6bc01"},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/studio-lab-user/Yolov9/yolov9\n"]}],"source":["%cd /home/studio-lab-user/Yolov9/yolov9"]},{"cell_type":"code","execution_count":null,"id":"5792dfd4-aafe-4a27-837e-f9ae3a82f5d6","metadata":{"tags":[],"id":"5792dfd4-aafe-4a27-837e-f9ae3a82f5d6","outputId":"af880b25-31a2-41ed-a292-23042f3287f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain_dual: \u001b[0mweights=/home/studio-lab-user/Yolov9/yolov9-e.pt, cfg=/home/studio-lab-user/Yolov9/yolov9/models/detect/yolov9-e.yaml, data=/home/studio-lab-user/Yolov9/PPE_Detection-2/data.yaml, hyp=/home/studio-lab-user/Yolov9/yolov9/data/hyps/hyp.scratch-high.yaml, epochs=50, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov9-e-finetuning, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=15, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","YOLO 🚀 v0.1-86-g1bbce4d Python-3.9.16 torch-2.2.2+cu121 CUDA:0 (Tesla T4, 14931MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO 🚀 in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1         0  models.common.Silence                   []                            \n","  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n","  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  3                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n","  4                -1  1    164352  models.common.ADown                     [256, 256]                    \n","  5                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n","  6                -1  1    656384  models.common.ADown                     [512, 512]                    \n","  7                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n","  8                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n","  9                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 10                 1  1      4160  models.common.CBLinear                  [64, [64]]                    \n"," 11                 3  1     49344  models.common.CBLinear                  [256, [64, 128]]              \n"," 12                 5  1    229824  models.common.CBLinear                  [512, [64, 128, 256]]         \n"," 13                 7  1    984000  models.common.CBLinear                  [1024, [64, 128, 256, 512]]   \n"," 14                 9  1   2033600  models.common.CBLinear                  [1024, [64, 128, 256, 512, 1024]]\n"," 15                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n"," 16[10, 11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[0, 0, 0, 0, 0]]             \n"," 17                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n"," 18[11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[1, 1, 1, 1]]                \n"," 19                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n"," 20                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 21  [12, 13, 14, -1]  1         0  models.common.CBFuse                    [[2, 2, 2]]                   \n"," 22                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n"," 23                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 24      [13, 14, -1]  1         0  models.common.CBFuse                    [[3, 3]]                      \n"," 25                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n"," 26                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n"," 27          [14, -1]  1         0  models.common.CBFuse                    [[4]]                         \n"," 28                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 29                 9  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 30                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 31           [-1, 7]  1         0  models.common.Concat                    [1]                           \n"," 32                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 33                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 34           [-1, 5]  1         0  models.common.Concat                    [1]                           \n"," 35                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 36                28  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 37                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 38          [-1, 25]  1         0  models.common.Concat                    [1]                           \n"," 39                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 40                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 41          [-1, 22]  1         0  models.common.Concat                    [1]                           \n"," 42                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 43                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 44          [-1, 39]  1         0  models.common.Concat                    [1]                           \n"," 45                -1  1   3612672  models.common.RepNCSPELAN4              [768, 512, 512, 256, 2]       \n"," 46                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 47          [-1, 36]  1         0  models.common.Concat                    [1]                           \n"," 48                -1  1  12860416  models.common.RepNCSPELAN4              [1024, 512, 1024, 512, 2]     \n"," 49[35, 32, 29, 42, 45, 48]  1  10992074  models.yolo.DualDDetect                 [7, [256, 512, 512, 256, 512, 512]]\n","yolov9-e summary: 1475 layers, 69417098 parameters, 69417066 gradients, 244.9 GFLOPs\n","\n","Transferred 2160/2172 items from /home/studio-lab-user/Yolov9/yolov9-e.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 356 weight(decay=0.0), 375 weight(decay=0.0005), 373 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/studio-lab-user/Yolov9/PPE_Detection-2/train/labels.cache.\u001b[0m\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /home/studio-lab-user/Yolov9/PPE_Detection-2/valid/labels.cache...\u001b[0m\n","Plotting labels to runs/train/yolov9-e-finetuning3/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 4 dataloader workers\n","Logging results to \u001b[1mruns/train/yolov9-e-finetuning3\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       0/49      11.7G      2.254      5.387      2.512         69        640:  Exception in thread Thread-5:\n","Traceback (most recent call last):\n","  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n","    self.run()\n","  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/threading.py\", line 917, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/home/studio-lab-user/Yolov9/yolov9/utils/plots.py\", line 300, in plot_images\n","    annotator.box_label(box, label, color=color)\n","  File \"/home/studio-lab-user/Yolov9/yolov9/utils/plots.py\", line 86, in box_label\n","    w, h = self.font.getsize(label)  # text width, height\n","AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n","WARNING ⚠️ TensorBoard graph visualization failure Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n","       0/49      12.9G      2.233       5.58      2.259         84        640:  Exception in thread Thread-6:\n","Traceback (most recent call last):\n","  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n","    self.run()\n","  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/threading.py\", line 917, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/home/studio-lab-user/Yolov9/yolov9/utils/plots.py\", line 300, in plot_images\n","    annotator.box_label(box, label, color=color)\n","  File \"/home/studio-lab-user/Yolov9/yolov9/utils/plots.py\", line 86, in box_label\n","    w, h = self.font.getsize(label)  # text width, height\n","AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n","       0/49      12.9G      2.182      5.542      2.332         40        640:  Exception in thread Thread-7:\n","Traceback (most recent call last):\n","  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n","    self.run()\n","  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/threading.py\", line 917, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/home/studio-lab-user/Yolov9/yolov9/utils/plots.py\", line 300, in plot_images\n","    annotator.box_label(box, label, color=color)\n","  File \"/home/studio-lab-user/Yolov9/yolov9/utils/plots.py\", line 86, in box_label\n","    w, h = self.font.getsize(label)  # text width, height\n","AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n","       0/49      13.6G      1.825      2.649      1.863         30        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.659      0.592      0.623      0.382\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/49        13G      1.648      1.598      1.681         73        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.684      0.652      0.692      0.431\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/49      14.4G      1.674       1.53      1.652         88        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.602      0.573      0.602      0.376\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/49      14.4G      1.731      1.543      1.693         53        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.772      0.622      0.701       0.42\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/49      14.4G      1.774        1.5      1.711         66        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.751      0.632      0.694      0.429\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/49      14.4G      1.717      1.407      1.685         89        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.787       0.66       0.72      0.439\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/49      14.4G      1.716       1.38      1.705         51        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.802      0.691       0.76      0.469\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/49      14.4G      1.675      1.331      1.668         81        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064       0.74      0.713      0.756      0.484\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/49      14.4G       1.65      1.281      1.654         36        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.899      0.651      0.748      0.478\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/49      14.4G      1.642       1.29       1.65         40        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.852      0.689      0.769      0.493\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      16/49      14.6G      1.494      1.061      1.556         89        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.834      0.755      0.811      0.525\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      17/49      14.6G      1.485      1.036      1.542         59        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.894       0.79      0.849      0.554\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      18/49      14.6G      1.456      1.015      1.536         44        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.842      0.769      0.823      0.549\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      19/49      14.6G      1.456      1.009      1.537         82        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.829      0.819      0.851      0.571\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      20/49      14.6G      1.451     0.9767      1.531         39        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.876      0.791      0.858      0.567\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      21/49      14.6G       1.43     0.9594      1.526         58        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.891      0.804      0.851      0.565\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      22/49      14.6G      1.404     0.9413      1.513         54        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064       0.87      0.806      0.858      0.578\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      23/49      14.6G       1.41     0.9365      1.497         75        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.896      0.803       0.86      0.578\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      24/49      14.6G       1.39     0.9253      1.498         71        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.871      0.817      0.874      0.593\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      25/49      14.6G      1.388      0.916      1.492         66        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.878      0.819      0.867      0.583\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      26/49      14.6G      1.362     0.8739      1.474         84        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.886      0.827       0.88      0.594\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      27/49      14.6G      1.354     0.8584      1.473         76        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.894      0.811      0.881      0.595\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      28/49      14.6G      1.352     0.8448      1.468         93        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.884      0.827      0.876      0.594\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      29/49      14.6G       1.32     0.8432      1.453         52        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.839      0.868      0.895      0.609\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      30/49      14.6G      1.323      0.818      1.454         41        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.904      0.845      0.901      0.622\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      31/49      14.6G      1.324     0.8169      1.456        140        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.916      0.854      0.906      0.617\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      32/49      14.6G      1.305     0.8066      1.466         56        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.915      0.832      0.896       0.61\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      33/49      14.6G      1.277     0.7736      1.435         71        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.878       0.85       0.89      0.614\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      34/49      14.6G      1.274     0.7721      1.434         49        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.925      0.821      0.897      0.613\n","Closing dataloader mosaic\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      35/49      14.6G      1.239     0.6944      1.488         44        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.897      0.837        0.9      0.628\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      36/49      14.6G      1.241     0.6859      1.481         24        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.906      0.845      0.903      0.629\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      37/49      14.6G       1.21     0.6603      1.459         26        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.903       0.85       0.91      0.627\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      38/49      14.6G      1.201     0.6347      1.464         28        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.899      0.838        0.9      0.633\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      39/49      14.6G      1.185     0.6357      1.453         18        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.887      0.883      0.924      0.641\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      40/49      14.6G      1.177      0.626      1.444         36        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.916      0.871      0.929      0.657\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      41/49      14.6G      1.153     0.6054      1.427         27        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.921      0.845      0.909      0.637\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      42/49      14.6G      1.148     0.5879      1.406         26        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.904      0.889      0.924      0.649\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      43/49      14.6G      1.126     0.5752      1.391         42        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.944      0.864      0.926      0.652\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      44/49      14.6G      1.117     0.5601      1.406         24        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.914      0.898      0.927      0.658\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      45/49      14.6G      1.099     0.5519      1.391         44        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.909      0.887       0.93      0.663\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      46/49      14.6G      1.074     0.5268      1.384         28        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.943      0.871      0.935      0.665\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      47/49      14.6G      1.086     0.5405      1.377         16        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.922      0.883      0.931      0.666\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      48/49      14.6G       1.06     0.5189      1.358         32        640: 1\n","                 Class     Images  Instances          P          R      mAP50   \n","                   all        637       3064      0.926      0.884       0.93      0.667\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      49/49      14.6G      1.048     0.5066      1.371         32        640:  "]}],"source":["!python /home/studio-lab-user/Yolov9/yolov9/train_dual.py --workers 8 --device 0 --batch 8 --data '/home/studio-lab-user/Yolov9/PPE_Detection-2/data.yaml' --img 640 --cfg /home/studio-lab-user/Yolov9/yolov9/models/detect/yolov9-e.yaml --weights '/home/studio-lab-user/Yolov9/yolov9-e.pt' --name yolov9-e-finetuning --hyp /home/studio-lab-user/Yolov9/yolov9/data/hyps/hyp.scratch-high.yaml --min-items 0 --epochs 50 --close-mosaic 15"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/newyolov9/yolov9"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6HohfIKZx7Ry","executionInfo":{"status":"ok","timestamp":1730623807438,"user_tz":-330,"elapsed":640,"user":{"displayName":"Palani P","userId":"17724790012365390628"}},"outputId":"bf465be9-93c0-485b-b4e6-8f8ffc729552"},"id":"6HohfIKZx7Ry","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/newyolov9/yolov9\n"]}]},{"cell_type":"code","execution_count":null,"id":"e4710c7c-a5c8-44f0-beb4-5ed5660bae93","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e4710c7c-a5c8-44f0-beb4-5ed5660bae93","executionInfo":{"status":"ok","timestamp":1730623983651,"user_tz":-330,"elapsed":124119,"user":{"displayName":"Palani P","userId":"17724790012365390628"}},"outputId":"e7ffe4d5-bb0d-41ae-f54b-72468bc5dcef"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval_dual: \u001b[0mdata=/content/drive/MyDrive/newyolov9/PPE_Detection-2/data.yaml, weights=['/content/drive/MyDrive/newyolov9/best (1).pt'], batch_size=16, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=0, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=yolov9_ppe_c_640_val, exist_ok=False, half=False, dnn=False, min_items=0\n","YOLO 🚀 v0.1-89-g93f1a28 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","/content/drive/MyDrive/newyolov9/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n","Fusing layers... \n","yolov9-e summary: 839 layers, 68557066 parameters, 0 gradients\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00<00:00, 12.0MB/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/newyolov9/PPE_Detection-2/valid/labels.cache... 637 images, 0 backgrounds, 0 corrupt: 100% 637/637 [00:00<?, ?it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95:   2% 1/40 [00:11<07:09, 11.03s/it]Exception in thread Thread-3 (plot_images):\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/content/drive/MyDrive/newyolov9/yolov9/utils/plots.py\", line 300, in plot_images\n","    annotator.box_label(box, label, color=color)\n","  File \"/content/drive/MyDrive/newyolov9/yolov9/utils/plots.py\", line 86, in box_label\n","    w, h = self.font.getsize(label)  # text width, height\n","AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n","Exception in thread Thread-4 (plot_images):\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/content/drive/MyDrive/newyolov9/yolov9/utils/plots.py\", line 300, in plot_images\n","    annotator.box_label(box, label, color=color)\n","  File \"/content/drive/MyDrive/newyolov9/yolov9/utils/plots.py\", line 86, in box_label\n","    w, h = self.font.getsize(label)  # text width, height\n","AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95:   5% 2/40 [00:12<03:29,  5.51s/it]Exception in thread Thread-5 (plot_images):\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/content/drive/MyDrive/newyolov9/yolov9/utils/plots.py\", line 300, in plot_images\n","    annotator.box_label(box, label, color=color)\n","  File \"/content/drive/MyDrive/newyolov9/yolov9/utils/plots.py\", line 86, in box_label\n","    w, h = self.font.getsize(label)  # text width, height\n","AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n","Exception in thread Thread-6 (plot_images):\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/content/drive/MyDrive/newyolov9/yolov9/utils/plots.py\", line 300, in plot_images\n","    annotator.box_label(box, label, color=color)\n","  File \"/content/drive/MyDrive/newyolov9/yolov9/utils/plots.py\", line 86, in box_label\n","    w, h = self.font.getsize(label)  # text width, height\n","AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95:   8% 3/40 [00:14<02:16,  3.70s/it]Exception in thread Thread-8 (plot_images):\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/content/drive/MyDrive/newyolov9/yolov9/utils/plots.py\", line 300, in plot_images\n","Exception in thread Thread-7 (plot_images):\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/content/drive/MyDrive/newyolov9/yolov9/utils/plots.py\", line 300, in plot_images\n","    annotator.box_label(box, label, color=color)\n","  File \"/content/drive/MyDrive/newyolov9/yolov9/utils/plots.py\", line 86, in box_label\n","    annotator.box_label(box, label, color=color)\n","  File \"/content/drive/MyDrive/newyolov9/yolov9/utils/plots.py\", line 86, in box_label\n","    w, h = self.font.getsize(label)  # text width, height\n","AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n","    w, h = self.font.getsize(label)  # text width, height\n","AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 40/40 [01:03<00:00,  1.60s/it]\n","                   all        637       3064      0.926      0.884       0.93      0.667\n","             Dust Mask        637        308      0.969      0.945      0.969      0.706\n","              Eye Wear        637        147      0.868       0.81      0.854      0.491\n","                 Glove        637        631      0.963      0.897      0.955      0.711\n","      Protective Boots        637        608      0.977      0.961      0.991      0.729\n","     Protective Helmet        637        753      0.966      0.953      0.984       0.78\n","           Safety Vest        637        592      0.878      0.889      0.936      0.726\n","                Shield        637         25      0.859      0.731      0.821      0.524\n","Speed: 0.2ms pre-process, 76.6ms inference, 2.3ms NMS per image at shape (16, 3, 640, 640)\n","\n","Evaluating pycocotools mAP... saving runs/val/yolov9_ppe_c_640_val3/best (1)_predictions.json...\n","loading annotations into memory...\n","pycocotools unable to run: [Errno 2] No such file or directory: '/content/drive/MyDrive/newyolov9/yolov9/annotations/instances_val2017.json'\n","Results saved to \u001b[1mruns/val/yolov9_ppe_c_640_val3\u001b[0m\n"]}],"source":["!python /content/drive/MyDrive/newyolov9/yolov9/val_dual.py --data '/content/drive/MyDrive/newyolov9/PPE_Detection-2/data.yaml' --img 640 --batch 16 --conf 0.001 --iou 0.7 --device 0 --weights '/content/drive/MyDrive/newyolov9/best (1).pt' --save-json --name yolov9_ppe_c_640_val\n"]},{"cell_type":"code","source":["!python /content/drive/MyDrive/newyolov9/yolov9/detect_dual.py --source '/content/drive/MyDrive/newyolov9/workwear-PPE-768x975 (1).jpg' --img 640 --device 0 --weights '/content/drive/MyDrive/newyolov9/best (1).pt' --name yolov9_c_ppe_640_detect"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UjRmVPQq2AHM","executionInfo":{"status":"ok","timestamp":1714237118682,"user_tz":-330,"elapsed":83385,"user":{"displayName":"Palani P","userId":"17724790012365390628"}},"outputId":"36543ffd-76db-49e4-ab79-ce129d7e04e0"},"id":"UjRmVPQq2AHM","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect_dual: \u001b[0mweights=['/content/drive/MyDrive/newyolov9/best (1).pt'], source=/content/drive/MyDrive/newyolov9/workwear-PPE-768x975 (1).jpg, data=drive/MyDrive/newyolov9/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=drive/MyDrive/newyolov9/yolov9/runs/detect, name=yolov9_c_ppe_640_detect, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLO 🚀 v0.1-89-g93f1a28 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","yolov9-e summary: 839 layers, 68557066 parameters, 0 gradients\n","image 1/1 /content/drive/MyDrive/newyolov9/workwear-PPE-768x975 (1).jpg: 640x512 1 Protective Helmet, 2 Safety Vests, 123.0ms\n","Speed: 0.7ms pre-process, 123.0ms inference, 890.2ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mdrive/MyDrive/newyolov9/yolov9/runs/detect/yolov9_c_ppe_640_detect\u001b[0m\n"]}]},{"cell_type":"code","source":["!python /content/drive/MyDrive/newyolov9/yolov9/detect_dual.py --source '/content/drive/MyDrive/newyolov9/ConstructionBlog2.png' --img 640 --device 0 --weights '/content/drive/MyDrive/newyolov9/best (1).pt' --name yolov9_c_ppe_640_detect"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WQiyZdPpgIOr","executionInfo":{"status":"ok","timestamp":1731392127022,"user_tz":-330,"elapsed":9599,"user":{"displayName":"Palani P","userId":"17724790012365390628"}},"outputId":"01317d64-6679-4e5a-d0f5-ed756f46800d"},"id":"WQiyZdPpgIOr","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect_dual: \u001b[0mweights=['/content/drive/MyDrive/newyolov9/best (1).pt'], source=/content/drive/MyDrive/newyolov9/ConstructionBlog2.png, data=drive/MyDrive/newyolov9/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=drive/MyDrive/newyolov9/yolov9/runs/detect, name=yolov9_c_ppe_640_detect, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLO 🚀 v0.1-89-g93f1a28 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","/content/drive/MyDrive/newyolov9/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n","Fusing layers... \n","yolov9-e summary: 839 layers, 68557066 parameters, 0 gradients\n","image 1/1 /content/drive/MyDrive/newyolov9/ConstructionBlog2.png: 448x640 2 Gloves, 3 Protective Helmets, 4 Safety Vests, 1 Shield, 94.3ms\n","Speed: 0.5ms pre-process, 94.3ms inference, 588.3ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mdrive/MyDrive/newyolov9/yolov9/runs/detect/yolov9_c_ppe_640_detect9\u001b[0m\n"]}]},{"cell_type":"code","source":["!python /content/drive/MyDrive/newyolov9/yolov9/detect_dual.py --source '/content/drive/MyDrive/newyolov9/png-clipart-man-wearing-orange-work-suit-hard-hats-occupational-safety-and-health-personal-protective-equipment-high-visibility-clothing-safety-people-orange-engineer.png' --img 640 --device 0 --weights '/content/drive/MyDrive/newyolov9/best (1).pt' --name yolov9_c_ppe_640_detect"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ErjsOwoFisz3","executionInfo":{"status":"ok","timestamp":1714237965477,"user_tz":-330,"elapsed":12060,"user":{"displayName":"Palani P","userId":"17724790012365390628"}},"outputId":"2e97d485-6fd1-493e-8a5f-f256c507047f"},"id":"ErjsOwoFisz3","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect_dual: \u001b[0mweights=['/content/drive/MyDrive/newyolov9/best (1).pt'], source=/content/drive/MyDrive/newyolov9/png-clipart-man-wearing-orange-work-suit-hard-hats-occupational-safety-and-health-personal-protective-equipment-high-visibility-clothing-safety-people-orange-engineer.png, data=drive/MyDrive/newyolov9/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=drive/MyDrive/newyolov9/yolov9/runs/detect, name=yolov9_c_ppe_640_detect, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLO 🚀 v0.1-89-g93f1a28 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","yolov9-e summary: 839 layers, 68557066 parameters, 0 gradients\n","image 1/1 /content/drive/MyDrive/newyolov9/png-clipart-man-wearing-orange-work-suit-hard-hats-occupational-safety-and-health-personal-protective-equipment-high-visibility-clothing-safety-people-orange-engineer.png: 640x448 3 Safety Vests, 1 Shield, 119.7ms\n","Speed: 0.6ms pre-process, 119.7ms inference, 456.0ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mdrive/MyDrive/newyolov9/yolov9/runs/detect/yolov9_c_ppe_640_detect3\u001b[0m\n"]}]},{"cell_type":"code","source":["!python /content/drive/MyDrive/newyolov9/yolov9/detect_dual.py --source '/content/drive/MyDrive/newyolov9/workwear-PPE-768x975 (1).jpg' --img 640 --device 0 --weights '/content/drive/MyDrive/newyolov9/best (1).pt' --name yolov9_c_ppe_640_detect"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7cJgOO9wPmVg","executionInfo":{"status":"ok","timestamp":1730624269659,"user_tz":-330,"elapsed":12428,"user":{"displayName":"Palani P","userId":"17724790012365390628"}},"outputId":"0dab65e0-9c29-4c2e-b5ca-69947a001855"},"id":"7cJgOO9wPmVg","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect_dual: \u001b[0mweights=['/content/drive/MyDrive/newyolov9/best (1).pt'], source=/content/drive/MyDrive/newyolov9/workwear-PPE-768x975 (1).jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=yolov9_c_ppe_640_detect, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLO 🚀 v0.1-89-g93f1a28 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","/content/drive/MyDrive/newyolov9/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n","Fusing layers... \n","yolov9-e summary: 839 layers, 68557066 parameters, 0 gradients\n","image 1/1 /content/drive/MyDrive/newyolov9/workwear-PPE-768x975 (1).jpg: 640x512 1 Protective Helmet, 2 Safety Vests, 119.9ms\n","Speed: 0.7ms pre-process, 119.9ms inference, 1035.9ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/yolov9_c_ppe_640_detect4\u001b[0m\n"]}]},{"cell_type":"code","source":["!python /content/drive/MyDrive/newyolov9/yolov9/detect_dual.py --source '/content/drive/MyDrive/newyolov9/ConstructionBlog2.png' --img 640 --device 0 --weights '/content/drive/MyDrive/newyolov9/best (1).pt' --name yolov9_c_ppe_640_detect"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-7pOXKFHrZiE","executionInfo":{"status":"ok","timestamp":1730648474043,"user_tz":-330,"elapsed":57155,"user":{"displayName":"Palani P","userId":"17724790012365390628"}},"outputId":"5a38746d-4085-49e8-d4af-403cf4af9651"},"id":"-7pOXKFHrZiE","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect_dual: \u001b[0mweights=['/content/drive/MyDrive/newyolov9/best (1).pt'], source=/content/drive/MyDrive/newyolov9/ConstructionBlog2.png, data=drive/MyDrive/newyolov9/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=drive/MyDrive/newyolov9/yolov9/runs/detect, name=yolov9_c_ppe_640_detect, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLO 🚀 v0.1-89-g93f1a28 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","/content/drive/MyDrive/newyolov9/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n","Fusing layers... \n","yolov9-e summary: 839 layers, 68557066 parameters, 0 gradients\n","image 1/1 /content/drive/MyDrive/newyolov9/ConstructionBlog2.png: 448x640 2 Gloves, 3 Protective Helmets, 4 Safety Vests, 1 Shield, 128.3ms\n","Speed: 0.8ms pre-process, 128.3ms inference, 1274.7ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mdrive/MyDrive/newyolov9/yolov9/runs/detect/yolov9_c_ppe_640_detect5\u001b[0m\n"]}]},{"cell_type":"code","source":["!python /content/drive/MyDrive/newyolov9/yolov9/detect_dual.py --source '/content/drive/MyDrive/newyolov9/images.jpeg' --img 640 --device 0 --weights '/content/drive/MyDrive/newyolov9/best (1).pt' --name yolov9_c_ppe_640_detect"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HnBRLNnYczwE","executionInfo":{"status":"ok","timestamp":1730694936503,"user_tz":-330,"elapsed":86506,"user":{"displayName":"Palani P","userId":"17724790012365390628"}},"outputId":"e940f248-fce6-4c53-b3a7-30f264fd86ff"},"id":"HnBRLNnYczwE","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect_dual: \u001b[0mweights=['/content/drive/MyDrive/newyolov9/best (1).pt'], source=/content/drive/MyDrive/newyolov9/images.jpeg, data=drive/MyDrive/newyolov9/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=drive/MyDrive/newyolov9/yolov9/runs/detect, name=yolov9_c_ppe_640_detect, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLO 🚀 v0.1-89-g93f1a28 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","/content/drive/MyDrive/newyolov9/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n","Fusing layers... \n","yolov9-e summary: 839 layers, 68557066 parameters, 0 gradients\n","image 1/1 /content/drive/MyDrive/newyolov9/images.jpeg: 384x640 3 Dust Masks, 1 Eye Wear, 3 Protective Helmets, 1 Safety Vest, 140.0ms\n","Speed: 0.7ms pre-process, 140.0ms inference, 1164.6ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mdrive/MyDrive/newyolov9/yolov9/runs/detect/yolov9_c_ppe_640_detect6\u001b[0m\n"]}]},{"cell_type":"code","source":["!python /content/drive/MyDrive/newyolov9/yolov9/detect_dual.py --source '/content/drive/MyDrive/newyolov9/WhatsApp Image 2024-11-04 at 10.07.50_858a5e91.jpg' --img 640 --device 0 --weights '/content/drive/MyDrive/newyolov9/best (1).pt' --name yolov9_c_ppe_640_detect"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W9FX9hnVeOtu","executionInfo":{"status":"ok","timestamp":1730695242092,"user_tz":-330,"elapsed":10727,"user":{"displayName":"Palani P","userId":"17724790012365390628"}},"outputId":"eb65f2aa-20e9-4111-87de-66e4894de53b"},"id":"W9FX9hnVeOtu","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect_dual: \u001b[0mweights=['/content/drive/MyDrive/newyolov9/best (1).pt'], source=/content/drive/MyDrive/newyolov9/WhatsApp Image 2024-11-04 at 10.07.50_858a5e91.jpg, data=drive/MyDrive/newyolov9/yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=drive/MyDrive/newyolov9/yolov9/runs/detect, name=yolov9_c_ppe_640_detect, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLO 🚀 v0.1-89-g93f1a28 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","/content/drive/MyDrive/newyolov9/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n","Fusing layers... \n","yolov9-e summary: 839 layers, 68557066 parameters, 0 gradients\n","image 1/1 /content/drive/MyDrive/newyolov9/WhatsApp Image 2024-11-04 at 10.07.50_858a5e91.jpg: 640x384 1 Shield, 86.6ms\n","Speed: 0.5ms pre-process, 86.6ms inference, 518.5ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mdrive/MyDrive/newyolov9/yolov9/runs/detect/yolov9_c_ppe_640_detect7\u001b[0m\n"]}]}],"metadata":{"kernelspec":{"display_name":"default:Python","language":"python","name":"conda-env-default-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}