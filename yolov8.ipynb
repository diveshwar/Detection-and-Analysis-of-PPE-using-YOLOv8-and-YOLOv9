{"cells":[{"cell_type":"code","execution_count":null,"id":"ac453bb4-b2f2-44dd-b3d2-a9348e491e38","metadata":{"id":"ac453bb4-b2f2-44dd-b3d2-a9348e491e38","outputId":"c9de3636-e34b-405c-92b6-42416f8bf389"},"outputs":[{"name":"stdout","output_type":"stream","text":["Name: ultralytics\n","Version: 8.1.27\n","Summary: Ultralytics YOLOv8 for SOTA object detection, multi-object tracking, instance segmentation, pose estimation and image classification.\n","Home-page: \n","Author: Glenn Jocher, Ayush Chaurasia, Jing Qiu\n","Author-email: \n","License: AGPL-3.0\n","Location: /home/u215978/.local/lib/python3.9/site-packages\n","Requires: matplotlib, opencv-python, pandas, pillow, psutil, py-cpuinfo, pyyaml, requests, scipy, seaborn, thop, torch, torchvision, tqdm\n","Required-by: \n"]}],"source":["!pip show ultralytics"]},{"cell_type":"code","execution_count":null,"id":"0509d2b8-99b5-47cb-a3b6-4325eb563704","metadata":{"id":"0509d2b8-99b5-47cb-a3b6-4325eb563704","outputId":"7e7736f8-899f-4448-af99-005475745123"},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Collecting roboflow\n","  Using cached roboflow-1.1.27-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: certifi==2023.7.22 in /glob/development-tools/versions/oneapi/2024.0.2.1/oneapi/intelpython/lib/python3.9/site-packages (from roboflow) (2023.7.22)\n","Collecting chardet==4.0.0 (from roboflow)\n","  Using cached chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n","Collecting cycler==0.10.0 (from roboflow)\n","  Using cached cycler-0.10.0-py2.py3-none-any.whl.metadata (722 bytes)\n","Collecting idna==2.10 (from roboflow)\n","  Using cached idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /glob/development-tools/versions/oneapi/2024.0.2.1/oneapi/intelpython/lib/python3.9/site-packages (from roboflow) (1.4.5)\n","Requirement already satisfied: matplotlib in /glob/development-tools/versions/oneapi/2024.0.2.1/oneapi/intelpython/lib/python3.9/site-packages (from roboflow) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /home/u215978/.local/lib/python3.9/site-packages (from roboflow) (1.26.4)\n","Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n","  Using cached opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n","Requirement already satisfied: Pillow>=7.1.2 in /glob/development-tools/versions/oneapi/2024.0.2.1/oneapi/intelpython/lib/python3.9/site-packages (from roboflow) (10.0.1)\n","Requirement already satisfied: python-dateutil in /glob/development-tools/versions/oneapi/2024.0.2.1/oneapi/intelpython/lib/python3.9/site-packages (from roboflow) (2.8.2)\n","Collecting python-dotenv (from roboflow)\n","  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: requests in /glob/development-tools/versions/oneapi/2024.0.2.1/oneapi/intelpython/lib/python3.9/site-packages (from roboflow) (2.31.0)\n","Requirement already satisfied: six in /glob/development-tools/versions/oneapi/2024.0.2.1/oneapi/intelpython/lib/python3.9/site-packages (from roboflow) (1.16.0)\n","Requirement already satisfied: urllib3>=1.26.6 in /glob/development-tools/versions/oneapi/2024.0.2.1/oneapi/intelpython/lib/python3.9/site-packages (from roboflow) (2.0.7)\n","Requirement already satisfied: tqdm>=4.41.0 in /glob/development-tools/versions/oneapi/2024.0.2.1/oneapi/intelpython/lib/python3.9/site-packages (from roboflow) (4.66.1)\n","Requirement already satisfied: PyYAML>=5.3.1 in /glob/development-tools/versions/oneapi/2024.0.2.1/oneapi/intelpython/lib/python3.9/site-packages (from roboflow) (6.0.1)\n","Collecting requests-toolbelt (from roboflow)\n","  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n","Collecting python-magic (from roboflow)\n","  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /glob/development-tools/versions/oneapi/2024.0.2.1/oneapi/intelpython/lib/python3.9/site-packages (from matplotlib->roboflow) (1.0.7)\n","Requirement already satisfied: fonttools>=4.22.0 in /glob/development-tools/versions/oneapi/2024.0.2.1/oneapi/intelpython/lib/python3.9/site-packages (from matplotlib->roboflow) (4.39.4)\n","Requirement already satisfied: packaging>=20.0 in /glob/development-tools/versions/oneapi/2024.0.2.1/oneapi/intelpython/lib/python3.9/site-packages (from matplotlib->roboflow) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /glob/development-tools/versions/oneapi/2024.0.2.1/oneapi/intelpython/lib/python3.9/site-packages (from matplotlib->roboflow) (3.1.1)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /glob/development-tools/versions/oneapi/2024.0.2.1/oneapi/intelpython/lib/python3.9/site-packages (from matplotlib->roboflow) (5.12.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /glob/development-tools/versions/oneapi/2024.0.2.1/oneapi/intelpython/lib/python3.9/site-packages (from requests->roboflow) (3.3.0)\n","Requirement already satisfied: zipp>=3.1.0 in /glob/development-tools/versions/oneapi/2024.0.2.1/oneapi/intelpython/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->roboflow) (3.17.0)\n","Using cached roboflow-1.1.27-py3-none-any.whl (74 kB)\n","Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n","Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n","Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n","Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n","Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: python-magic, python-dotenv, opencv-python-headless, idna, cycler, chardet, requests-toolbelt, roboflow\n","  Attempting uninstall: opencv-python-headless\n","    Found existing installation: opencv-python-headless 4.9.0.80\n","    Uninstalling opencv-python-headless-4.9.0.80:\n","      Successfully uninstalled opencv-python-headless-4.9.0.80\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 1.4.3 requires opencv-python-headless>=4.9.0, but you have opencv-python-headless 4.8.0.74 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-dotenv-1.0.1 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.27\n"]}],"source":["!pip install roboflow"]},{"cell_type":"code","execution_count":null,"id":"ca83ff09-f3e8-4e16-84cf-8663ada133d5","metadata":{"id":"ca83ff09-f3e8-4e16-84cf-8663ada133d5","outputId":"868de376-5184-4eab-b3ed-6641fa941ccb"},"outputs":[{"name":"stdout","output_type":"stream","text":["loading Roboflow workspace...\n","loading Roboflow project...\n","Dependency ultralytics==8.0.196 is required but found version=8.1.27, to fix: `pip install ultralytics==8.0.196`\n"]},{"name":"stderr","output_type":"stream","text":["Downloading Dataset Version Zip in PPE_Detection-2 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 198176/198176 [00:54<00:00, 3605.20it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n"]},{"name":"stderr","output_type":"stream","text":["Extracting Dataset Version Zip to PPE_Detection-2 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6472/6472 [00:18<00:00, 356.30it/s]\n"]}],"source":["\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"F37pg4gr42c1PivmIqV0\")\n","project = rf.workspace(\"project-uyrxf\").project(\"ppe_detection-v1x3l\")\n","version = project.version(2)\n","dataset = version.download(\"yolov8\")"]},{"cell_type":"code","execution_count":null,"id":"4df6f4a0-ff70-434c-aeea-32c5dc056744","metadata":{"id":"4df6f4a0-ff70-434c-aeea-32c5dc056744","outputId":"76d68016-55ac-47b1-a86e-4f3e8f7e111e"},"outputs":[{"name":"stdout","output_type":"stream","text":["New https://pypi.org/project/ultralytics/8.2.2 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n","Ultralytics YOLOv8.1.27 ðŸš€ Python-3.9.18 torch-2.2.1+cu121 CPU (Intel Xeon Gold 6128 3.40GHz)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/home/u215978/new yolov8/PPE_Detection-2/data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n","Overriding model.yaml nc=80 with nc=7\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    752677  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n","Model summary: 225 layers, 3012213 parameters, 3012197 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/u215978/new yolov8/PPE_Detection-2/train/labels.cache... 2\u001b[0m\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /home/u215978/new yolov8/PPE_Detection-2/valid/labels.cache... 637\u001b[0m\n","Plotting labels to runs/detect/train2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n","Image sizes 640 train, 640 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1mruns/detect/train2\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/50         0G      1.509      2.707      1.391         92        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all        637       3064      0.667      0.508      0.508      0.287\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/50         0G      1.397      1.697      1.303        133        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all        637       3064      0.712      0.546      0.581      0.346\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/50         0G      1.389      1.502      1.282        109        640: 1\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all        637       3064      0.788      0.598      0.658      0.379\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/50         0G      1.352      1.472      1.287         81        640:  "]}],"source":["!yolo task=detect mode=train epochs=50 data='/home/u215978/new yolov8/PPE_Detection-2/data.yaml' model=yolov8n.pt imgsz=640"]},{"cell_type":"code","execution_count":null,"id":"8fb4bbe1-ce06-4ae5-b949-47d6b3860f99","metadata":{"tags":[],"id":"8fb4bbe1-ce06-4ae5-b949-47d6b3860f99","outputId":"905af74d-477d-4336-a667-b66a3ce6770d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.1.27 ðŸš€ Python-3.9.18 torch-2.2.1+cu121 CPU (Intel Xeon Gold 6128 3.40GHz)\n","Model summary (fused): 168 layers, 3007013 parameters, 0 gradients, 8.1 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /home/u215978/new yolov8/PPE_Detection-2/valid/labels.cache... 637\u001b[0m\n","                 Class     Images  Instances      Box(P          R      mAP50  m\n","                   all        637       3064      0.905      0.835      0.893      0.625\n","             Dust Mask        637        308      0.974      0.916      0.971      0.678\n","              Eye Wear        637        147       0.88        0.7      0.821      0.473\n","                 Glove        637        631      0.976      0.889      0.937       0.67\n","      Protective Boots        637        608       0.97      0.951      0.984      0.699\n","     Protective Helmet        637        753      0.958       0.95      0.985      0.753\n","           Safety Vest        637        592      0.877      0.878      0.929      0.715\n","                Shield        637         25      0.698       0.56      0.628      0.385\n","Speed: 1.5ms preprocess, 38.6ms inference, 0.0ms loss, 0.6ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val4\u001b[0m\n","ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"]}],"source":["!yolo task=detect mode=val model='/home/u215978/new yolov8/runs/detect/train/weights/best.pt' data = '/home/u215978/new yolov8/PPE_Detection-2/data.yaml'"]},{"cell_type":"code","execution_count":null,"id":"8c18ff36-a70f-42c4-8944-6932d9c61733","metadata":{"id":"8c18ff36-a70f-42c4-8944-6932d9c61733","outputId":"5bb53d31-0dff-4a57-8eae-d8c8298a9671"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.1.27 ðŸš€ Python-3.9.18 torch-2.2.1+cu121 CPU (Intel Xeon Gold 6128 3.40GHz)\n","Model summary (fused): 168 layers, 3007013 parameters, 0 gradients, 8.1 GFLOPs\n","\n","image 1/1 /home/u215978/new yolov8/workwear-PPE-768x975.jpg: 640x512 1 Protective Helmet, 1 Safety Vest, 577.9ms\n","Speed: 94.1ms preprocess, 577.9ms inference, 124.1ms postprocess per image at shape (1, 3, 640, 512)\n","Results saved to \u001b[1mruns/detect/predict\u001b[0m\n","ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"]}],"source":["!yolo task=detect mode=predict model='/home/u215978/new yolov8/runs/detect/train/weights/best.pt' source='/home/u215978/new yolov8/workwear-PPE-768x975.jpg' save=True"]},{"cell_type":"code","execution_count":null,"id":"5e139d74-e709-4223-b719-870a3d00e4b9","metadata":{"id":"5e139d74-e709-4223-b719-870a3d00e4b9","outputId":"f53afa09-406e-4c92-f866-c654f4554952"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.1.27 ðŸš€ Python-3.9.18 torch-2.2.1+cu121 CPU (Intel Xeon Gold 6128 3.40GHz)\n","Model summary (fused): 168 layers, 3007013 parameters, 0 gradients, 8.1 GFLOPs\n","\n","image 1/1 /home/u215978/new yolov8/im.png: 640x448 1 Glove, 1 Protective Helmet, 1 Safety Vest, 49.8ms\n","Speed: 27.8ms preprocess, 49.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n","Results saved to \u001b[1mruns/detect/predict3\u001b[0m\n","ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"]}],"source":["!yolo task=detect mode=predict model='/home/u215978/new yolov8/runs/detect/train/weights/best.pt' source='/home/u215978/new yolov8/im.png' save=True"]},{"cell_type":"code","execution_count":null,"id":"85df4b9e-f932-481b-8386-294c2a87f64a","metadata":{"id":"85df4b9e-f932-481b-8386-294c2a87f64a","outputId":"75340f98-0ccb-44cc-a8a6-102ea9b54172"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.1.27 ðŸš€ Python-3.9.18 torch-2.2.1+cu121 CPU (Intel Xeon Gold 6128 3.40GHz)\n","Model summary (fused): 168 layers, 3007013 parameters, 0 gradients, 8.1 GFLOPs\n","\n","image 1/1 /home/u215978/new yolov8/ConstructionBlog2.png: 448x640 4 Protective Helmets, 2 Safety Vests, 66.6ms\n","Speed: 2.3ms preprocess, 66.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n","Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n","ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"]}],"source":["!yolo task=detect mode=predict model='/home/u215978/new yolov8/runs/detect/train/weights/best.pt' source='/home/u215978/new yolov8/ConstructionBlog2.png' save=True"]},{"cell_type":"code","execution_count":null,"id":"07ec60dd-d67d-449b-afab-0014392a22b4","metadata":{"id":"07ec60dd-d67d-449b-afab-0014392a22b4"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (IntelÂ® oneAPI 2024.1)","language":"python","name":"c009-intel_distribution_of_python_3_oneapi-beta05-python-2024.1"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}